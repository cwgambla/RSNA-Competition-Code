{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":52254,"databundleVersionId":6307054,"sourceType":"competition"},{"sourceId":6276893,"sourceType":"datasetVersion","datasetId":3608788},{"sourceId":6462237,"sourceType":"datasetVersion","datasetId":3731975},{"sourceId":6485815,"sourceType":"datasetVersion","datasetId":3747503},{"sourceId":6686236,"sourceType":"datasetVersion","datasetId":3856605},{"sourceId":139612149,"sourceType":"kernelVersion"}],"isInternetEnabled":false,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# <center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\n# This starter notebook is provided by the Keras team.</center>\n\n# %% [markdown]\n# # Inference Notebook\n# \n# # RSNA 2023 Abdominal Trauma Detection with [KerasCV](https://github.com/keras-team/keras-cv) and [KerasCore](https://github.com/keras-team/keras-core)\n# \n# This notebook walks you through how to submit to the RSNA 2023 Abdominal Trauma Detection competition.\n# \n# ## Notebooks\n# \n# For this competition we have two starter notebook. This notebook (you are reading) infers on the trained model. To understand how the model was trained from scratch please visit the training kernel.\n# \n# 1. [**Training Kernel**](https://www.kaggle.com/code/aritrag/kerascv-starter-notebook-train)\n# 2. [**Inference Kernel**](https://www.kaggle.com/code/aritrag/kerascv-starter-notebook-infer)\n# \n# **Note**: [KerasCV guides](https://keras.io/guides/keras_cv/) is the place to go for a deeper understanding of KerasCV individually.\n\n# %% [markdown]\n# # Imports and Setup\n# \n# Please install namex, keras-cv and keras-core for this notebook to work!\n# \n# Note: We will very soon have keras and keras models accessible from offline notebook =D \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-12T20:09:43.879291Z\",\"iopub.execute_input\":\"2023-09-12T20:09:43.879757Z\",\"iopub.status.idle\":\"2023-09-12T20:11:26.174968Z\",\"shell.execute_reply.started\":\"2023-09-12T20:09:43.879719Z\",\"shell.execute_reply\":\"2023-09-12T20:11:26.173433Z\"}}\n! pip install -q /kaggle/input/keras-cv-core-namex/namex-0.0.7-py3-none-any.whl\n! pip install -q /kaggle/input/keras-cv-core-namex/keras_core-0.1.4-py3-none-any.whl\n! pip install -q /kaggle/input/keras-cv-core-namex/keras_cv-0.6.1-py3-none-any.whl\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:23:56.864302Z\",\"iopub.execute_input\":\"2023-10-13T17:23:56.864751Z\",\"iopub.status.idle\":\"2023-10-13T17:23:56.872465Z\",\"shell.execute_reply.started\":\"2023-10-13T17:23:56.864721Z\",\"shell.execute_reply\":\"2023-10-13T17:23:56.871129Z\"}}\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport keras_core as keras\nimport keras_cv\n\nimport gc\nimport cv2\nimport pydicom\nfrom joblib import Parallel, delayed\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom glob import glob\n\n# %% [code]\nBASE_PATH = \"/kaggle/input/rsna-2023-abdominal-trauma-detection\"\nIMAGE_DIR = \"/tmp/dataset/rsna-atd\"\nINPUT_MODEL_PATH = \"/kaggle/input/efficient-bo-v1/efficientnet_b0_2.701.pth\"\nMODEL_PATH = \"/kaggle/input/efficient-bo-v1/efficientnet_b0_2.701.pth\"\nSTRIDE = 10\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:24:00.760527Z\",\"iopub.execute_input\":\"2023-10-13T17:24:00.761946Z\",\"iopub.status.idle\":\"2023-10-13T17:24:00.770964Z\",\"shell.execute_reply.started\":\"2023-10-13T17:24:00.761889Z\",\"shell.execute_reply\":\"2023-10-13T17:24:00.769971Z\"}}\nclass Config:\n    IMAGE_SIZE = [256, 256]\n    RESIZE_DIM = 256\n    BATCH_SIZE = 64\n    AUTOTUNE = tf.data.AUTOTUNE\n    TARGET_COLS  = [\"bowel_healthy\", \"bowel_injury\", \"extravasation_healthy\",\n                   \"extravasation_injury\", \"kidney_healthy\", \"kidney_low\",\n                   \"kidney_high\", \"liver_healthy\", \"liver_low\", \"liver_high\",\n                   \"spleen_healthy\", \"spleen_low\", \"spleen_high\"]\n\nconfig = Config()\n\n# %% [markdown]\n# # Initialize the Trained Model\n# \n# Refer to the [training kernel](https://www.kaggle.com/code/aritrag/kerascv-starter-notebook-train) to understand how we have trained the model.\n# \n# Here we initialize the trained model.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:24:24.039682Z\",\"iopub.execute_input\":\"2023-10-13T17:24:24.040330Z\",\"iopub.status.idle\":\"2023-10-13T17:24:24.123328Z\",\"shell.execute_reply.started\":\"2023-10-13T17:24:24.040300Z\",\"shell.execute_reply\":\"2023-10-13T17:24:24.121770Z\"}}\n# ! cp {INPUT_MODEL_PATH} ./\nimport pickle\nmodel = torch.load(\"/kaggle/input/efficient-bo-v1/efficientnet_b0_2.701.pth\")\nmodel.summary()\n\n# %% [markdown]\n# # Data Pipeline\n# \n# We have a model that accepts image in the PNG format. We will now convert the DICOM images to PNG for the model to infer.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:21:09.885210Z\",\"iopub.execute_input\":\"2023-10-13T17:21:09.885694Z\",\"iopub.status.idle\":\"2023-10-13T17:21:09.920596Z\",\"shell.execute_reply.started\":\"2023-10-13T17:21:09.885650Z\",\"shell.execute_reply\":\"2023-10-13T17:21:09.919211Z\"}}\nmeta_df = pd.read_csv(f\"{BASE_PATH}/test_series_meta.csv\")\n\n# Checking if patients are repeated by finding the number of unique patient IDs\nnum_rows = meta_df.shape[0]\nunique_patients = meta_df[\"patient_id\"].nunique()\n\nprint(f\"{num_rows=}\")\nprint(f\"{unique_patients=}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:21:11.557430Z\",\"iopub.execute_input\":\"2023-10-13T17:21:11.558256Z\",\"iopub.status.idle\":\"2023-10-13T17:21:11.618971Z\",\"shell.execute_reply.started\":\"2023-10-13T17:21:11.558199Z\",\"shell.execute_reply\":\"2023-10-13T17:21:11.617783Z\"}}\nmeta_df[\"dicom_folder\"] = BASE_PATH + \"/\" + \"test_images\"\\\n                                    + \"/\" + meta_df.patient_id.astype(str)\\\n                                    + \"/\" + meta_df.series_id.astype(str)\n\ntest_folders = meta_df.dicom_folder.tolist()\ntest_paths = []\nfor folder in tqdm(test_folders):\n    test_paths += sorted(glob(os.path.join(folder, \"*dcm\")))[::STRIDE]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:21:13.035264Z\",\"iopub.execute_input\":\"2023-10-13T17:21:13.035712Z\",\"iopub.status.idle\":\"2023-10-13T17:21:13.067315Z\",\"shell.execute_reply.started\":\"2023-10-13T17:21:13.035678Z\",\"shell.execute_reply\":\"2023-10-13T17:21:13.066159Z\"}}\ntest_df = pd.DataFrame(test_paths, columns=[\"dicom_path\"])\ntest_df[\"patient_id\"] = test_df.dicom_path.map(lambda x: x.split(\"/\")[-3]).astype(int)\ntest_df[\"series_id\"] = test_df.dicom_path.map(lambda x: x.split(\"/\")[-2]).astype(int)\ntest_df[\"instance_number\"] = test_df.dicom_path.map(lambda x: x.split(\"/\")[-1].replace(\".dcm\",\"\")).astype(int)\n\ntest_df[\"image_path\"] = f\"{IMAGE_DIR}/test_images\"\\\n                    + \"/\" + test_df.patient_id.astype(str)\\\n                    + \"/\" + test_df.series_id.astype(str)\\\n                    + \"/\" + test_df.instance_number.astype(str) +\".png\"\n\ntest_df.head(2)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:21:15.047687Z\",\"iopub.execute_input\":\"2023-10-13T17:21:15.048137Z\",\"iopub.status.idle\":\"2023-10-13T17:21:15.055394Z\",\"shell.execute_reply.started\":\"2023-10-13T17:21:15.048102Z\",\"shell.execute_reply\":\"2023-10-13T17:21:15.053929Z\"}}\n# Checking if patients are repeated by finding the number of unique patient IDs\nnum_rows = test_df.shape[0]\nunique_patients = test_df[\"patient_id\"].nunique()\n\nprint(f\"{num_rows=}\")\nprint(f\"{unique_patients=}\")\n\n# %% [markdown]\n# ## DICOM to PNG pipeline\n\n# %% [code] {\"_kg_hide-input\":true}\n# !rm -r {IMAGE_DIR}\nos.makedirs(f\"{IMAGE_DIR}/train_images\", exist_ok=True)\nos.makedirs(f\"{IMAGE_DIR}/test_images\", exist_ok=True)\n\n# %% [code] {\"_kg_hide-input\":true,\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:22:02.037270Z\",\"iopub.execute_input\":\"2023-10-13T17:22:02.038194Z\",\"iopub.status.idle\":\"2023-10-13T17:22:02.051412Z\",\"shell.execute_reply.started\":\"2023-10-13T17:22:02.038123Z\",\"shell.execute_reply\":\"2023-10-13T17:22:02.049937Z\"}}\ndef standardize_pixel_array(dcm):\n    # Correct DICOM pixel_array if PixelRepresentation == 1.\n    pixel_array = dcm.pixel_array\n    if dcm.PixelRepresentation == 1:\n        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n        dtype = pixel_array.dtype \n        new_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n        pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n    return pixel_array\n\ndef read_xray(path, fix_monochrome=True):\n    dicom = pydicom.dcmread(path)\n    data = standardize_pixel_array(dicom)\n    data = data - np.min(data)\n    data = data / (np.max(data) + 1e-5)\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = 1.0 - data\n    return data\n\ndef resize_and_save(file_path):\n    img = read_xray(file_path)\n    h, w = img.shape[:2]  # orig hw\n    img = cv2.resize(img, (config.RESIZE_DIM, config.RESIZE_DIM), cv2.INTER_LINEAR)\n    img = (img * 255).astype(np.uint8)\n    \n    sub_path = file_path.split(\"/\",4)[-1].split(\".dcm\")[0] + \".png\"\n    infos = sub_path.split(\"/\")\n    sub_path = file_path.split(\"/\",4)[-1].split(\".dcm\")[0] + \".png\"\n    infos = sub_path.split(\"/\")\n    pid = infos[-3]\n    sid = infos[-2]\n    iid = infos[-1]; iid = iid.replace(\".png\",\"\")\n    new_path = os.path.join(IMAGE_DIR, sub_path)\n    os.makedirs(new_path.rsplit(\"/\",1)[0], exist_ok=True)\n    cv2.imwrite(new_path, img)\n    return\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:22:04.859651Z\",\"iopub.execute_input\":\"2023-10-13T17:22:04.860110Z\",\"iopub.status.idle\":\"2023-10-13T17:22:05.592766Z\",\"shell.execute_reply.started\":\"2023-10-13T17:22:04.860073Z\",\"shell.execute_reply\":\"2023-10-13T17:22:05.591525Z\"}}\n%%time\n\nfile_paths = test_df.dicom_path.tolist()\n_ = Parallel(n_jobs=2, backend=\"threading\")(\n    delayed(resize_and_save)(file_path) for file_path in tqdm(file_paths, leave=True, position=0)\n)\n\ndel _; gc.collect()\n\n# %% [markdown]\n# ## Building the tf.data pipeline\n\n# %% [code] {\"_kg_hide-input\":true,\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:22:09.541610Z\",\"iopub.execute_input\":\"2023-10-13T17:22:09.542667Z\",\"iopub.status.idle\":\"2023-10-13T17:22:09.557165Z\",\"shell.execute_reply.started\":\"2023-10-13T17:22:09.542632Z\",\"shell.execute_reply\":\"2023-10-13T17:22:09.556149Z\"}}\ndef decode_image(image_path):\n    file_bytes = tf.io.read_file(image_path)\n    image = tf.io.decode_png(file_bytes, channels=3, dtype=tf.uint8)\n    image = tf.image.resize(image, config.IMAGE_SIZE, method=\"bilinear\")\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\ndef build_dataset(image_paths):\n    ds = (\n        tf.data.Dataset.from_tensor_slices(image_paths)\n        .map(decode_image, num_parallel_calls=config.AUTOTUNE)\n        .shuffle(config.BATCH_SIZE * 10)\n        .batch(config.BATCH_SIZE)\n        .prefetch(config.AUTOTUNE)\n    )\n    return ds\n\ndef build_dataset(image_paths):\n    ds = (\n        tf.data.Dataset.from_tensor_slices(image_paths)\n        .map(decode_image, num_parallel_calls=config.AUTOTUNE)\n        .shuffle(config.BATCH_SIZE * 10)\n        .batch(config.BATCH_SIZE)\n        .prefetch(config.AUTOTUNE)\n    )\n    return ds\n\n# %% [code] {\"_kg_hide-input\":true,\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:22:11.693878Z\",\"iopub.execute_input\":\"2023-10-13T17:22:11.694421Z\",\"iopub.status.idle\":\"2023-10-13T17:22:11.872901Z\",\"shell.execute_reply.started\":\"2023-10-13T17:22:11.694378Z\",\"shell.execute_reply\":\"2023-10-13T17:22:11.871506Z\"}}\npaths  = test_df.image_path.tolist()\n\nds = build_dataset(paths)\nimages = next(iter(ds))\n\nimages.shape\n\n# %% [code] {\"_kg_hide-input\":true,\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:22:13.701581Z\",\"iopub.execute_input\":\"2023-10-13T17:22:13.702049Z\",\"iopub.status.idle\":\"2023-10-13T17:22:14.046659Z\",\"shell.execute_reply.started\":\"2023-10-13T17:22:13.702001Z\",\"shell.execute_reply\":\"2023-10-13T17:22:14.045230Z\"}}\nkeras_cv.visualization.plot_image_gallery(\n    images=images,\n    value_range=(0, 1),\n    rows=1,\n    cols=3,\n)\n\n# %% [markdown]\n# # Inference\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:22:16.241867Z\",\"iopub.execute_input\":\"2023-10-13T17:22:16.243510Z\",\"iopub.status.idle\":\"2023-10-13T17:22:16.251680Z\",\"shell.execute_reply.started\":\"2023-10-13T17:22:16.243464Z\",\"shell.execute_reply\":\"2023-10-13T17:22:16.250326Z\"}}\ndef post_proc(pred):\n    proc_pred = np.empty((pred.shape[0], 2*2 + 3*3), dtype=\"float32\")\n\n    # bowel, extravasation\n    proc_pred[:, 0] = pred[:, 0]\n    proc_pred[:, 1] = 1 - proc_pred[:, 0]\n    proc_pred[:, 2] = pred[:, 1]\n    proc_pred[:, 3] = 1 - proc_pred[:, 2]\n    \n    # liver, kidney, sneel\n    proc_pred[:, 4:7] = pred[:, 2:5]\n    proc_pred[:, 7:10] = pred[:, 5:8]\n    proc_pred[:, 10:13] = pred[:, 8:11]\n\n    return proc_pred\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-10-13T17:22:27.541203Z\",\"iopub.execute_input\":\"2023-10-13T17:22:27.541582Z\",\"iopub.status.idle\":\"2023-10-13T17:22:27.647949Z\",\"shell.execute_reply.started\":\"2023-10-13T17:22:27.541555Z\",\"shell.execute_reply\":\"2023-10-13T17:22:27.645621Z\"}}\n# Getting unique patient IDs from test dataset\npatient_ids = test_df[\"patient_id\"].unique()\n\n# Initializing array to store predictions\npatient_preds = np.zeros(\n    shape=(len(patient_ids), 2*2 + 3*3),\n    dtype=\"float32\"\n)\n\n# Iterating over each patient\nfor pidx, patient_id5 in tqdm(enumerate(patient_ids), total=len(patient_ids), desc=\"Patients \"):\n    print(f\"Patient ID: {patient_id5}\")\n    \n    # Query the dataframe for a particular patient\n    patient_df = test_df.query(f\"patient_id == {patient_id5}\")\n    \n    # Getting image paths for a patient\n    patient_paths = patient_df.image_path.tolist()\n\n    # Building dataset for prediction\n    dtest = build_dataset(patient_paths)\n    \n    # Predicting with the model\n    pred = model(dtest)\n    pred = np.concatenate(pred, axis=-1).astype(\"float32\")\n    pred = pred[:len(patient_paths), :]\n    pred = np.mean(pred.reshape(1, len(patient_paths), 11), axis=0)\n    pred = np.max(pred, axis=0, keepdims=True)\n    \n    patient_preds[pidx, :] += post_proc(pred)[0]\n    \n\n    # Deleting variables to free up memory \n    del patient_df, patient_paths, dtest, pred; gc.collect()\n\n# %% [markdown]\n# # Submission\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-12T20:12:01.171428Z\",\"iopub.execute_input\":\"2023-09-12T20:12:01.172220Z\",\"iopub.status.idle\":\"2023-09-12T20:12:02.310247Z\",\"shell.execute_reply.started\":\"2023-09-12T20:12:01.172133Z\",\"shell.execute_reply\":\"2023-09-12T20:12:02.309033Z\"}}\n# !rm -rf {MODEL_PATH}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-12T20:12:23.082287Z\",\"iopub.execute_input\":\"2023-09-12T20:12:23.082691Z\",\"iopub.status.idle\":\"2023-09-12T20:12:23.123432Z\",\"shell.execute_reply.started\":\"2023-09-12T20:12:23.082660Z\",\"shell.execute_reply\":\"2023-09-12T20:12:23.122430Z\"}}\n# Create Submission\npred_df = pd.DataFrame({\"patient_id\":patient_ids,})\npred_df[config.TARGET_COLS] = patient_preds.astype(\"float32\")\n\n# Align with sample submission\nsub_df = pd.read_csv(f\"{BASE_PATH}/sample_submission.csv\")\nsub_df = sub_df[[\"patient_id\"]]\nsub_df = sub_df.merge(pred_df, on=\"patient_id\", how=\"left\")\n\n# Store submission\nsub_df.to_csv(\"submission.csv\",index=False)\nsub_df.head(2)","metadata":{"_uuid":"ed591e69-9b56-495b-b097-59fa2dc0aee6","_cell_guid":"40afedce-bfdd-4e02-aad8-caee35e2cbd9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}